name: Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test]"
        
    - name: Lint with flake8
      run: |
        flake8 src tests --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src tests --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
        
    - name: Type check with mypy
      run: |
        mypy src --ignore-missing-imports
        
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=term --cov-fail-under=80
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: true
        verbose: true

  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: claude_tui_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test]"
        
    - name: Set up Node.js for Claude Flow
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Install Claude Flow
      run: |
        npm install -g claude-flow@alpha
        
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/claude_tui_test
        CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
        CLAUDE_TUI_ENV: test
      run: |
        pytest tests/integration/ -v --timeout=60 --maxfail=5
    
  ui-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test]"
        
    - name: Run TUI tests
      run: |
        pytest tests/ui/ -v --timeout=30
        
  validation-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test]"
        
    - name: Run anti-hallucination validation tests
      run: |
        pytest tests/validation/ -v --timeout=45
        
    - name: Generate validation report
      run: |
        pytest tests/validation/ --json-report --json-report-file=validation-report.json
        
    - name: Upload validation report
      uses: actions/upload-artifact@v3
      with:
        name: validation-report
        path: validation-report.json

  security-tests:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test,security]"
        
    - name: Run security tests
      run: |
        pytest tests/security/ -v --timeout=30
        
    - name: Run Bandit security scan
      run: |
        bandit -r src/ -f json -o bandit-report.json
        
    - name: Run Safety check
      run: |
        safety check --json --output safety-report.json
        
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  performance-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,test]"
        
    - name: Run performance tests
      run: |
        pytest tests/performance/ -v -m "performance" --timeout=300
        
    - name: Run benchmarks
      run: |
        pytest tests/performance/ -v -m "benchmark" --benchmark-json=benchmark-results.json
        
    - name: Store benchmark results
      uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'pytest'
        output-file-path: benchmark-results.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        comment-on-alert: true
        alert-threshold: '150%'
        fail-on-alert: false

  test-summary:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, ui-tests, validation-tests, security-tests]
    if: always()
    
    steps:
    - name: Generate test summary
      run: |
        echo "## ðŸ§ª Test Suite Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Test Category | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|---------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| Unit Tests | ${{ needs.unit-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} | Core functionality tests |" >> $GITHUB_STEP_SUMMARY
        echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} | CLI and external service tests |" >> $GITHUB_STEP_SUMMARY
        echo "| UI Tests | ${{ needs.ui-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} | Terminal interface tests |" >> $GITHUB_STEP_SUMMARY
        echo "| Validation Tests | ${{ needs.validation-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} | Anti-hallucination tests |" >> $GITHUB_STEP_SUMMARY
        echo "| Security Tests | ${{ needs.security-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} | Security and input validation |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š Coverage Report" >> $GITHUB_STEP_SUMMARY
        echo "Coverage reports are available in the test artifacts." >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸš€ Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "- Review any failing tests" >> $GITHUB_STEP_SUMMARY
        echo "- Check coverage requirements (minimum 80%)" >> $GITHUB_STEP_SUMMARY
        echo "- Address security scan findings" >> $GITHUB_STEP_SUMMARY
        echo "- Monitor performance benchmarks" >> $GITHUB_STEP_SUMMARY