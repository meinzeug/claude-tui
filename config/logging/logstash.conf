# Logstash Configuration for Claude TIU
# Centralized log processing and forwarding

input {
  # Application logs from files
  file {
    path => ["/app/logs/*.log", "/app/logs/**/*.log"]
    start_position => "beginning"
    type => "application"
    tags => ["claude-tiu", "application"]
    codec => multiline {
      pattern => "^\d{4}-\d{2}-\d{2}"
      negate => true
      what => "previous"
    }
  }

  # Docker container logs
  docker {
    host => "unix:///var/run/docker.sock"
    type => "docker"
    tags => ["docker", "containers"]
  }

  # Syslog input
  syslog {
    port => 514
    type => "syslog"
    tags => ["system", "syslog"]
  }

  # HTTP input for webhook logs
  http {
    port => 8080
    type => "webhook"
    tags => ["webhook", "api"]
  }

  # Beats input (Filebeat, Metricbeat, etc.)
  beats {
    port => 5044
    type => "beats"
  }

  # TCP input for structured logs
  tcp {
    port => 5000
    codec => json_lines
    type => "structured"
  }
}

filter {
  # Parse timestamp
  if [type] == "application" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:level} - %{DATA:logger} - %{GREEDYDATA:message}" 
      }
      overwrite => [ "message" ]
    }
    
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }

    # Parse structured JSON logs
    if [message] =~ /^{.*}$/ {
      json {
        source => "message"
      }
    }
  }

  # Docker container log processing
  if [type] == "docker" {
    # Extract container metadata
    mutate {
      add_field => { "container_id" => "%{[docker][id]}" }
      add_field => { "container_name" => "%{[docker][name]}" }
      add_field => { "image_name" => "%{[docker][image]}" }
    }

    # Parse application logs from containers
    if [container_name] =~ /claude-tiu/ {
      grok {
        match => { 
          "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:level} - %{DATA:logger} - %{GREEDYDATA:log_message}" 
        }
      }
      
      mutate {
        replace => { "message" => "%{log_message}" }
      }
    }
  }

  # HTTP/API log processing
  if [type] == "webhook" {
    # Parse common log formats
    grok {
      match => { 
        "message" => "%{COMBINEDAPACHELOG}" 
      }
      tag_on_failure => ["_grokparsefailure_http"]
    }

    # Parse user agent
    if [agent] {
      useragent {
        source => "agent"
      }
    }

    # GeoIP lookup
    if [clientip] {
      geoip {
        source => "clientip"
        target => "geoip"
      }
    }
  }

  # Security log processing
  if [tags] and "security" in [tags] {
    # Parse security events
    grok {
      match => { 
        "message" => "SECURITY_EVENT: %{WORD:event_type} - %{DATA:event_details} - IP: %{IP:source_ip} - User: %{USER:username}" 
      }
      tag_on_failure => ["_grokparsefailure_security"]
    }

    # Add security severity
    if [event_type] == "FAILED_LOGIN" {
      mutate {
        add_field => { "security_severity" => "medium" }
      }
    } else if [event_type] == "BRUTE_FORCE" {
      mutate {
        add_field => { "security_severity" => "high" }
      }
    } else if [event_type] == "PRIVILEGE_ESCALATION" {
      mutate {
        add_field => { "security_severity" => "critical" }
      }
    }
  }

  # Performance log processing
  if [tags] and "performance" in [tags] {
    # Parse performance metrics
    grok {
      match => { 
        "message" => "PERF: %{WORD:metric_name} = %{NUMBER:metric_value:float} %{WORD:metric_unit} - Duration: %{NUMBER:duration:float}ms" 
      }
      tag_on_failure => ["_grokparsefailure_performance"]
    }
  }

  # Error log processing
  if [level] == "ERROR" or [level] == "CRITICAL" {
    # Extract stack traces
    grok {
      match => { 
        "message" => "(?<error_type>[A-Za-z]+Error|Exception): %{GREEDYDATA:error_message}" 
      }
      tag_on_failure => ["_grokparsefailure_error"]
    }

    # Add error severity
    if [level] == "CRITICAL" {
      mutate {
        add_field => { "error_severity" => "critical" }
      }
    } else {
      mutate {
        add_field => { "error_severity" => "high" }
      }
    }
  }

  # Add common fields
  mutate {
    add_field => { "service" => "claude-tiu" }
    add_field => { "environment" => "${ENVIRONMENT:development}" }
    add_field => { "version" => "${APP_VERSION:unknown}" }
    add_field => { "hostname" => "%{host}" }
  }

  # Clean up fields
  mutate {
    remove_field => [ "log", "@version" ]
  }

  # Convert numeric fields
  if [response_time] {
    mutate {
      convert => { "response_time" => "integer" }
    }
  }

  if [status_code] {
    mutate {
      convert => { "status_code" => "integer" }
    }
  }

  # Add tags based on content
  if [message] =~ /(?i)error|exception|fail|fatal/ {
    mutate {
      add_tag => [ "error" ]
    }
  }

  if [message] =~ /(?i)warn|warning/ {
    mutate {
      add_tag => [ "warning" ]
    }
  }

  if [message] =~ /(?i)security|auth|login|permission/ {
    mutate {
      add_tag => [ "security" ]
    }
  }

  if [message] =~ /(?i)performance|latency|slow|timeout/ {
    mutate {
      add_tag => [ "performance" ]
    }
  }

  # Database query logs
  if [logger] =~ /sqlalchemy|database/ {
    mutate {
      add_tag => [ "database" ]
    }
    
    # Extract SQL queries
    grok {
      match => { 
        "message" => "(?<sql_operation>SELECT|INSERT|UPDATE|DELETE|CREATE|DROP|ALTER) %{GREEDYDATA:sql_query}" 
      }
      tag_on_failure => ["_grokparsefailure_sql"]
    }
  }

  # AI service logs
  if [logger] =~ /ai|claude|openai/ {
    mutate {
      add_tag => [ "ai_service" ]
    }
  }

  # API endpoint logs
  if [message] =~ /(?i)(GET|POST|PUT|DELETE|PATCH)\s+\/api\// {
    grok {
      match => { 
        "message" => "%{WORD:http_method} %{URIPATH:api_endpoint}" 
      }
    }
    
    mutate {
      add_tag => [ "api" ]
    }
  }
}

output {
  # Elasticsearch for log storage and search
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:localhost:9200}"]
    index => "claude-tiu-logs-%{+YYYY.MM.dd}"
    template_name => "claude-tiu"
    template_pattern => "claude-tiu-*"
    template_overwrite => true
    template => "/usr/share/logstash/templates/claude-tiu-template.json"
  }

  # Separate indices for different log types
  if "error" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST:localhost:9200}"]
      index => "claude-tiu-errors-%{+YYYY.MM.dd}"
    }
  }

  if "security" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST:localhost:9200}"]
      index => "claude-tiu-security-%{+YYYY.MM.dd}"
    }
  }

  if "performance" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST:localhost:9200}"]
      index => "claude-tiu-performance-%{+YYYY.MM.dd}"
    }
  }

  # Send to Kafka for real-time processing
  kafka {
    topic_id => "claude-tiu-logs"
    bootstrap_servers => "${KAFKA_BROKERS:localhost:9092}"
    codec => json
  }

  # Alert on critical errors
  if [level] == "CRITICAL" or [error_severity] == "critical" {
    http {
      url => "${ALERT_WEBHOOK_URL}"
      http_method => "post"
      format => "json"
      headers => {
        "Content-Type" => "application/json"
        "Authorization" => "Bearer ${ALERT_TOKEN}"
      }
      mapping => {
        "severity" => "critical"
        "service" => "claude-tiu"
        "message" => "%{message}"
        "timestamp" => "%{@timestamp}"
        "environment" => "%{environment}"
      }
    }
  }

  # Send security events to SIEM
  if "security" in [tags] {
    tcp {
      host => "${SIEM_HOST}"
      port => "${SIEM_PORT:514}"
      codec => json
    }
  }

  # File output for debugging
  if "${DEBUG_MODE:false}" == "true" {
    file {
      path => "/tmp/logstash-debug.log"
      codec => rubydebug
    }
  }

  # Stdout for development
  if "${ENVIRONMENT}" == "development" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }

  # Metrics output to monitoring system
  statsd {
    host => "${STATSD_HOST:localhost}"
    port => "${STATSD_PORT:8125}"
    namespace => "claude-tiu.logs"
    sender => "logstash"
    increment => [
      "total_logs",
      "logs_by_level.%{level}",
      "logs_by_service.%{service}",
      "logs_by_environment.%{environment}"
    ]
  }
}